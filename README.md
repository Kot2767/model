Описание:
  Этот проект представляет собой нейроадаптивную систему, предназначенную для анализа видео- и аудиопотоков, распознавания жестов, движений рук и устной речи, а также преобразования их в текст. Система основана на использовании библиотек OpenCV и нейросетевых моделей, таких как CNN, RNN и механизм внимания (Attention).

Цель:
  Разработка системы, способной обрабатывать устную и маноральную речь для улучшения разборчивости при физических или когнитивных нарушениях.

Основные задачи:
  Анализ современных методов обработки устной и маноральной речи.
  Разработка алгоритмов обработки видеоизображений для распознавания жестов.
  Тестирование системы на реальных данных и оценка её эффективности.
  Оптимизация системы для работы в реальном времени.

Архитектура системы:
  Обработка видео: Используются OpenCV и MediaPipe для выделения ключевых точек и анализа движений.
  Распознавание жестов: CNN и RNN модели для анализа жестов и движений.
  Обработка аудио: AdvancedLSTM, MultiHeadAttention и MultiScaleCNN для обработки аудиосигналов.
  Трансформер: Объединяет все механизмы для генерации связного текста.

Преимущества:
  Адаптивность к различным типам нарушений речи.
  Высокая точность распознавания жестов и речи.
  Возможность обработки данных в реальном времени.
  Универсальность и поддержка загрузки видеофайлов.

Тестирование:
  Точность распознавания жестов: 94.2% на тестовом наборе данных.
  Условия слабого освещения: точность жестов 87.3%.
  Фоновый шум 60 дБ: WER увеличивается до 12.1%.
  Быстрые движения: сохраняется точность 89.8%.

Установка и запуск:
  Установите необходимые зависимости:
    pip install opencv-python mediapipe tensorflow torch librosa soundfile numpy
  Запустите основной файл:
    python all.py
